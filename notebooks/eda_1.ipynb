{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pydicom\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import ipyvolume as ipv\n",
    "import volumentations as V\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_folder  = r\"C:\\KAGGLE\\MEDICINE\\data\\train_images\\10004\\51033\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_files = os.listdir(dicom_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Source : https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/discussion/427217\n",
    "    \"\"\"\n",
    "    # Correct DICOM pixel_array if PixelRepresentation == 1.\n",
    "    pixel_array = dcm.pixel_array\n",
    "    if dcm.PixelRepresentation == 1:\n",
    "        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n",
    "        dtype = pixel_array.dtype \n",
    "        pixel_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n",
    "#         pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n",
    "\n",
    "    intercept = float(dcm.RescaleIntercept)\n",
    "    slope = float(dcm.RescaleSlope)\n",
    "    center = int(dcm.WindowCenter)\n",
    "    width = int(dcm.WindowWidth)\n",
    "    low = center - width / 2\n",
    "    high = center + width / 2    \n",
    "    \n",
    "    pixel_array = (pixel_array * slope) + intercept\n",
    "    pixel_array = np.clip(pixel_array, low, high)\n",
    "\n",
    "    return pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data_path=\"\", size=512):\n",
    "    lst_files = os.listdir(data_path)\n",
    "    lst_files = [int(x[:-4]) for x  in lst_files]\n",
    "    print(len(lst_files))\n",
    "    lst_files.sort()\n",
    "    if len(lst_files) > 1200:\n",
    "        lst_files = lst_files[150:-150]\n",
    "    elif len(lst_files) > 900:\n",
    "        lst_files = lst_files[100:-100]\n",
    "    print(len(lst_files))\n",
    "    \n",
    "    imgs = []\n",
    "    if len(lst_files) > 1500:\n",
    "        step = 5\n",
    "    elif len(lst_files) > 1200:\n",
    "        step = 3\n",
    "    elif\n",
    "    elif len(lst_files) > 600:\n",
    "        step = 2\n",
    "    else:\n",
    "        step = 1\n",
    "    step = 1\n",
    "    for f in range(min(lst_files), max(lst_files) + 1, step):\n",
    "        path_to_files = os.path.join(data_path, f\"{f}.dcm\")\n",
    "\n",
    "        dicom = pydicom.dcmread(path_to_files)\n",
    "\n",
    "        pos_z = dicom[(0x20, 0x32)].value[-1]\n",
    "\n",
    "        img = standardize_pixel_array(dicom)\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "\n",
    "        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            img = 1 - img\n",
    "\n",
    "    \n",
    "        if img.shape != (512, 512):\n",
    "            img = cv2.resize(img, (size, size))\n",
    "\n",
    "        imgs.append(img)\n",
    "\n",
    "    combined_array = np.stack(imgs, axis=0)\n",
    "    \n",
    "    combined_array = np.transpose(combined_array, [1, 2, 0])\n",
    "    return combined_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new = process(data_path=dicom_folder, size=512)\n",
    "img = img_new\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3D_segmentations(filepath, downsample_rate=1):\n",
    "    \"\"\"\n",
    "    Стандартные лейблы были:\n",
    "    1 - liver \n",
    "    2 - spleen\n",
    "    3 - kidney_left\n",
    "    4 - kidney_right\n",
    "    5 - bowel \n",
    "    Изменю структуру, чтобы было более удобно на такой вариант \n",
    "\n",
    "    1 - liver \n",
    "    2 - spleen \n",
    "    3 - kidney (r & l)\n",
    "    4 - bowel \n",
    "    \"\"\"\n",
    "    img = nib.load(filepath).get_fdata()\n",
    "    img = np.transpose(img, [1, 0, 2])\n",
    "    img = np.rot90(img, 1, (1,2))\n",
    "    img = img[::-1,:,:]\n",
    "    img = np.transpose(img, [1, 0, 2])\n",
    "    img = img[::downsample_rate, ::downsample_rate, ::downsample_rate]\n",
    "    img = np.transpose(img, [1, 2, 0])\n",
    "    img = np.round(img).astype(int)\n",
    "\n",
    "    # 4 -> 3 \n",
    "    img = np.where(img == 4, 3, img)\n",
    "    # 5 -> 4\n",
    "    img = np.where(img == 5, 4, img)\n",
    "    print(img.shape)\n",
    "    print(img.shape[2])\n",
    "    print('aaaaa')\n",
    "    if img.shape[2] > 1300:\n",
    "        img = img[...,150:-150]\n",
    "    elif img.shape[2] > 1000:\n",
    "        img = img[...,100:-100]\n",
    "    print(img.shape)\n",
    "    \n",
    "\n",
    "    if img.shape[2] > 1500:\n",
    "        step = 5\n",
    "    elif img.shape[2] > 1200:\n",
    "        step = 3\n",
    "    elif img.shape[2] > 800:\n",
    "        step = 2\n",
    "    else:\n",
    "        step = 1\n",
    "    step = 1\n",
    "    return img[..., ::step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     patient_id  series_id  count_layer              size  count_layers_seg  \\\n29        15876      38633          725   (512, 512, 725)               725   \n172       55888      13925          730   (512, 512, 730)               730   \n3         10228      30522          747   (512, 512, 747)               747   \n202        7642        778          751   (512, 512, 751)               751   \n159       52416      54830          762   (512, 512, 762)               762   \n112       38238      32670          763   (512, 512, 763)               763   \n12        11652      39013          768   (512, 512, 768)               768   \n145       47263      57769          768   (512, 512, 768)               768   \n139       45488      30064          773   (512, 512, 773)               773   \n155       50873      18207          788   (512, 512, 788)               788   \n182       60836      47856          797   (512, 512, 797)               797   \n157       51545      22730          804   (512, 512, 804)               804   \n163       54183      33526          827   (512, 512, 827)               827   \n185       62116      10180          828   (512, 512, 828)               828   \n140       45488       4890          835   (512, 512, 835)               835   \n188       62397      62307          843   (512, 512, 843)               843   \n136       44507      21282          850   (512, 512, 850)               850   \n152       50753       4759          861   (512, 512, 861)               861   \n0         10004      21057         1022  (512, 512, 1022)              1022   \n1         10004      51033         1044  (512, 512, 1044)              1044   \n\n     same  \n29   True  \n172  True  \n3    True  \n202  True  \n159  True  \n112  True  \n12   True  \n145  True  \n139  True  \n155  True  \n182  True  \n157  True  \n163  True  \n185  True  \n140  True  \n188  True  \n136  True  \n152  True  \n0    True  \n1    True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>series_id</th>\n      <th>count_layer</th>\n      <th>size</th>\n      <th>count_layers_seg</th>\n      <th>same</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29</th>\n      <td>15876</td>\n      <td>38633</td>\n      <td>725</td>\n      <td>(512, 512, 725)</td>\n      <td>725</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>55888</td>\n      <td>13925</td>\n      <td>730</td>\n      <td>(512, 512, 730)</td>\n      <td>730</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10228</td>\n      <td>30522</td>\n      <td>747</td>\n      <td>(512, 512, 747)</td>\n      <td>747</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>7642</td>\n      <td>778</td>\n      <td>751</td>\n      <td>(512, 512, 751)</td>\n      <td>751</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>52416</td>\n      <td>54830</td>\n      <td>762</td>\n      <td>(512, 512, 762)</td>\n      <td>762</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>38238</td>\n      <td>32670</td>\n      <td>763</td>\n      <td>(512, 512, 763)</td>\n      <td>763</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11652</td>\n      <td>39013</td>\n      <td>768</td>\n      <td>(512, 512, 768)</td>\n      <td>768</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>47263</td>\n      <td>57769</td>\n      <td>768</td>\n      <td>(512, 512, 768)</td>\n      <td>768</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>45488</td>\n      <td>30064</td>\n      <td>773</td>\n      <td>(512, 512, 773)</td>\n      <td>773</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>50873</td>\n      <td>18207</td>\n      <td>788</td>\n      <td>(512, 512, 788)</td>\n      <td>788</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>60836</td>\n      <td>47856</td>\n      <td>797</td>\n      <td>(512, 512, 797)</td>\n      <td>797</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>51545</td>\n      <td>22730</td>\n      <td>804</td>\n      <td>(512, 512, 804)</td>\n      <td>804</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>54183</td>\n      <td>33526</td>\n      <td>827</td>\n      <td>(512, 512, 827)</td>\n      <td>827</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>62116</td>\n      <td>10180</td>\n      <td>828</td>\n      <td>(512, 512, 828)</td>\n      <td>828</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>45488</td>\n      <td>4890</td>\n      <td>835</td>\n      <td>(512, 512, 835)</td>\n      <td>835</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>62397</td>\n      <td>62307</td>\n      <td>843</td>\n      <td>(512, 512, 843)</td>\n      <td>843</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>44507</td>\n      <td>21282</td>\n      <td>850</td>\n      <td>(512, 512, 850)</td>\n      <td>850</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>50753</td>\n      <td>4759</td>\n      <td>861</td>\n      <td>(512, 512, 861)</td>\n      <td>861</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>10004</td>\n      <td>21057</td>\n      <td>1022</td>\n      <td>(512, 512, 1022)</td>\n      <td>1022</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10004</td>\n      <td>51033</td>\n      <td>1044</td>\n      <td>(512, 512, 1044)</td>\n      <td>1044</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../src_upd/data_for_segmentation.csv\")\n",
    "data.sort_values(\"count_layer\").tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 850)\n",
      "850\n",
      "aaaaa\n",
      "(512, 512, 850)\n",
      "(512, 512, 850)\n",
      "CPU times: total: 2.97 s\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ТОЛЬКО ПОЧКИ \n",
    "path_to_mask = r\"C:\\KAGGLE\\MEDICINE\\data\\segmentations\\21282.nii\"\n",
    "mask_data = create_3D_segmentations(path_to_mask)\n",
    "print(mask_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcdd14473974e93ab913a288481f826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Container(children=[VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.1, max=1.0, step…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создайте трехмерную визуализацию\n",
    "fig = ipv.figure()\n",
    "\n",
    "# Отобразите объемные данные\n",
    "# vol = ipv.volshow( img +  mask_data, lighting=True)\n",
    "vol = ipv.volshow(   mask_data )\n",
    "# Добавьте интерактивность (вращение, масштабирование и т.д.)\n",
    "ipv.style.box_off()\n",
    "ipv.style.axes_off()\n",
    "ipv.style.set_style_light()\n",
    "\n",
    "# Покажите визуализацию\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor =  F.interpolate(\n",
    "            torch.tensor(img).unsqueeze(0).unsqueeze(0),\n",
    "            size=(192, 192, 192),\n",
    "            mode='trilinear',\n",
    "            align_corners=False\n",
    "        )[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 192, 192])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 522)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentaion_aug = V.Compose([\n",
    "    V.Resize((192, 192, 192), interpolation=3, resize_type=0, always_apply=True, p=1.0),\n",
    "], p=1.0)\n",
    "data_for_aug = {\"image\": img, 'mask': mask_data}\n",
    "new_data = segmentaion_aug(**data_for_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_mask = new_data['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(upd_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_img = new_data['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = img_tensor.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), (192, 192, 192))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_data = np.round(upd_mask).astype(int)\n",
    "condition = ((mask_data != 2) )\n",
    "\n",
    "mask_data = np.where(condition, 0, 1) \n",
    "np.unique(mask_data), mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_new = img[:,:,400:800]\n",
    "# img_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Project_python\\kaggle_3d\\myenv\\lib\\site-packages\\ipyvolume\\serialize.py:102: RuntimeWarning: invalid value encountered in cast\n",
      "  subdata[..., i] = ((gradient[i][zindex] / 2.0 + 0.5) * 255).astype(np.uint8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e083f3152b4242a64af700a326068b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Container(children=[VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.1, max=1.0, step…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_data = nib.load(path_to_mask).get_fdata()\n",
    "mask_data = np.round(mask_data).astype(int)\n",
    "\n",
    "condition = ((mask_data != 3) & (mask_data != 4)) \n",
    "mask_data = np.where(condition, 0, 1) \n",
    "np.unique(mask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3D_segmentations(filepath, downsample_rate=1):\n",
    "    img = nib.load(filepath).get_fdata()\n",
    "    img = np.transpose(img, [1, 0, 2])\n",
    "    img = np.rot90(img, 1, (1,2))\n",
    "    img = img[::-1,:,:]\n",
    "    img = np.transpose(img, [1, 0, 2])\n",
    "    img = img[::downsample_rate, ::downsample_rate, ::downsample_rate]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data = create_3D_segmentations(\"../data/segmentations/7334.nii\")\n",
    "mask_data = np.round(mask_data).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
